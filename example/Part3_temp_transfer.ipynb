{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from importlib import reload\n",
    "import networkx as nx\n",
    "\n",
    "sys.path.insert(0, '/path/to/temp_graph/')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from nff.train import Trainer, get_trainer, get_model, loss, hooks, metrics, evaluate, load_model\n",
    "from torch.optim import Adam\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import nff.data as d\n",
    "import pickle\n",
    "\n",
    "from nff.data import Dataset, split_train_validation_test, collate_dicts, sparsify_tensor\n",
    "from nff.io.ase import * \n",
    "from nff.nn.glue import Stack\n",
    "\n",
    "from ase import Atoms\n",
    "from ase.neighborlist import neighbor_list\n",
    "from nff.data.sparse import sparsify_array\n",
    "\n",
    "from nff.md.nvt import * \n",
    "from ase import units\n",
    "from nff.io import NeuralFF\n",
    "from nff.md.nve import * \n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader():\n",
    "    ## There are more file names, because when training on the full dataset with \n",
    "    ## multiple temperatures, all of them are loaded together\n",
    "    PATH = './data'\n",
    "    CG_PATH1 = '{}/p300_CG_T300_intra7_inter8.pkl'.format(PATH)\n",
    "#     CG_PATH2 = '{}/p300_CG{}_T350_intra7_inter8.pkl'.format(PATH, CG_key)\n",
    "#     CG_PATH3 = '{}/p300_CG{}_T450_intra7_inter8.pkl'.format(PATH, CG_key)\n",
    "#     CG_PATH4 = '{}/p300_CG{}_T500_intra7_inter8.pkl'.format(PATH, CG_key)\n",
    "\n",
    "    props = pickle.load( open( CG_PATH1, \"rb\" ) )\n",
    "#     props2 = pickle.load( open( CG_PATH2, \"rb\" ) )\n",
    "#     props3 = pickle.load( open( CG_PATH3, \"rb\" ) )\n",
    "#     props4 = pickle.load( open( CG_PATH4, \"rb\" ) )\n",
    "\n",
    "    props['cell'] = [torch.Tensor(props['cell'][i]) for i, cell in enumerate(props['cell'])]\n",
    "#     props2['cell'] = [torch.Tensor(props2['cell'][i]) for i, cell in enumerate(props2['cell'])]\n",
    "#     props3['cell'] = [torch.Tensor(props3['cell'][i]) for i, cell in enumerate(props3['cell'])]\n",
    "#     props4['cell'] = [torch.Tensor(props4['cell'][i]) for i, cell in enumerate(props4['cell'])]\n",
    "\n",
    "#     for key in props:\n",
    "#         props[key] = props[key] + props2[key] + props3[key] + props4[key]\n",
    "\n",
    "    bond_dic = {'CCCC': [[5 * i, 5 * i + 1,\n",
    "                          5 * i + 1, 5 * i + 2,\n",
    "                          5 * i + 2, 5 * i + 3] for i in range(300)]}\n",
    "    bond_dic['CCCC'] = torch.LongTensor( np.array(bond_dic['CCCC']).reshape(900,2).tolist())\n",
    "\n",
    "#     bond_dic = {'CCCC': [[3 * i, 3 * i + 1] for i in range(300)]}\n",
    "#     bond_dic['CCCC'] = torch.LongTensor( np.array(bond_dic['CCCC']).reshape(300,2).tolist())\n",
    "    \n",
    "    # xyz = torch.Tensor([props['nxyz'][i][:,1:4] for i in range(len(props['nxyz']))])\n",
    "\n",
    "    # r = (xyz[:, bond_dic['CCCC'][:,0]] - xyz[:, bond_dic['CCCC'][:,1]]).pow(2).sum(-1).sqrt()\n",
    "\n",
    "    # print(r.reshape(-1, 300, 3)[:,:,0].mean())\n",
    "    # print(r.reshape(-1, 300, 3)[:,:,1].mean())\n",
    "    # print(r.reshape(-1, 300, 3)[:,:,2].mean())\n",
    "\n",
    "    props['bonds'] = [bond_dic['CCCC'] for i in range(len(props['nxyz']))]\n",
    "    props['num_bonds'] = [torch.LongTensor([3]) for i in range(len(props['nxyz']))]\n",
    "    props['bond_len'] = [torch.Tensor([2.2439, 2.8182, 2.5558]) for i in range(len(props['nxyz']))]\n",
    "\n",
    "    props['smiles'] = ['CCCC'] * len(props['nxyz'])\n",
    "    \n",
    "    temp = 1/np.array([300,350,450,500])\n",
    "    props['temp'] = torch.cat([torch.zeros(597)+temp[0]])#,torch.zeros(5997)+temp[1],\n",
    "#                               torch.zeros(5997)+temp[2],torch.zeros(5997)+temp[3]])\n",
    "\n",
    "    dataset = d.Dataset(props.copy(), units='kcal/mol')\n",
    "\n",
    "    train, val, test = split_train_validation_test(dataset, val_size=0.1, test_size=0.01)\n",
    "\n",
    "    train_loader = DataLoader(train, batch_size=1, collate_fn=collate_dicts)\n",
    "    val_loader = DataLoader(val, batch_size=1, collate_fn=collate_dicts)\n",
    "    test_loader = DataLoader(test, batch_size=1, collate_fn=collate_dicts)\n",
    "    \n",
    "    return dataset, train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, train_loader, val_loader, test_loader = data_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.utils import batch_to\n",
    "batch = batch_to( next(iter(train_loader)), \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the default model, without any changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for the model described in the paper\n",
    "modelparams = dict()\n",
    "modelparams['n_atom_basis'] = 160\n",
    "modelparams['n_filters'] = 256\n",
    "modelparams['n_gaussians'] = 64\n",
    "modelparams['mol_n_convolutions'] = 3\n",
    "modelparams['sys_n_convolutions'] = 3\n",
    "modelparams['mol_cutoff'] = 7\n",
    "modelparams['sys_cutoff'] = 8\n",
    "modelparams[\"V_ex_power\"] = 10\n",
    "modelparams[\"V_ex_sigma\"] = 3.8553023965125024\n",
    "modelparams['dropout_rate'] = 0\n",
    "modelparams['temp_type'] = 'mult'\n",
    "\n",
    "bondparams = dict()\n",
    "bondparams['k'] = 20.758080279097705\n",
    "bondparams['dif_bond_len'] = True\n",
    "\n",
    "bondprior = get_model(bondparams, model_type='BondPrior')\n",
    "temp_transfer = get_model(modelparams, model_type='cg_temp_graph')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'energy': tensor([[2583.6365]], grad_fn=<AsStridedBackward>),\n",
       " 'energy_grad': tensor([[ -0.7953,   0.8832,  -0.1094],\n",
       "         [  2.7098,  -2.4491,  -4.9452],\n",
       "         [ -0.0282, -13.7677,   6.2763],\n",
       "         ...,\n",
       "         [ -1.7269, -21.3974,   4.8554],\n",
       "         [  0.9095,  20.0323, -11.3076],\n",
       "         [ -1.9408,   1.0884,  -0.9409]], grad_fn=<AddBackward0>)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nff.nn.glue import Stack\n",
    "model_dict = dict()\n",
    "model_dict['bondprior'] = bondprior\n",
    "model_dict['temp_transfer'] = temp_transfer\n",
    "stack = Stack(model_dict, mode='sum')\n",
    "stack(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTDIR = './example/training/dummy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exists\n"
     ]
    }
   ],
   "source": [
    "loss_fn = loss.build_mse_loss(loss_coef={'energy_grad': 1})\n",
    "\n",
    "\n",
    "trainable_params = filter(lambda p: p.requires_grad, stack.parameters()) # CHANGE PARAMTERS\n",
    "optimizer = Adam(trainable_params, lr=3e-4)\n",
    "\n",
    "\n",
    "train_metrics = [\n",
    "    metrics.MeanAbsoluteError('energy_grad')\n",
    "]\n",
    "\n",
    "from shutil import rmtree\n",
    "import os\n",
    "\n",
    "train_hooks = [\n",
    "    hooks.MaxEpochHook(100),\n",
    "    hooks.CSVHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "    ),\n",
    "    hooks.PrintingHook(\n",
    "        OUTDIR,\n",
    "        metrics=train_metrics,\n",
    "        separator = ' | ',\n",
    "        time_strf='%M:%S'\n",
    "    ),\n",
    "    hooks.ReduceLROnPlateauHook(\n",
    "        optimizer=optimizer,\n",
    "        patience=30,\n",
    "        factor=0.5,\n",
    "        min_lr=1e-7,\n",
    "        window_length=1,\n",
    "        stop_after_min=True\n",
    "    )\n",
    "]\n",
    "\n",
    "if os.path.exists(OUTDIR):\n",
    "    print('exists')\n",
    "    rmtree(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = Trainer(\n",
    "    model_path=OUTDIR,\n",
    "    model=stack,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    validation_loader=val_loader,\n",
    "    checkpoint_interval=1,\n",
    "    hooks=train_hooks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Time | Epoch | Learning rate | Train loss | Validation loss | MAE_energy_grad | GPU Memory (MB)\n",
      "25:54 |     1 |     3.000e-04 |   309.8748 |        298.8344 |         12.3961 |             522\n"
     ]
    }
   ],
   "source": [
    "T.train(device=0, n_epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase import Atoms\n",
    "from ase.neighborlist import neighbor_list\n",
    "from nff.data.sparse import sparsify_array\n",
    "\n",
    "from nff.md.nvt import * \n",
    "from ase import units\n",
    "from nff.io import NeuralFF\n",
    "from nff.md.nve import * \n",
    "\n",
    "\n",
    "DEFAULT_CUTOFF = 5.0\n",
    "\n",
    "system_prop = {key: val[0] for key, val in dataset.props.items()}\n",
    "system_prop['atoms_cutoff'] = 7\n",
    "system_prop['system_cutoff'] = 8\n",
    "system_prop['temp'] = torch.zeros(1)+1/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nff.io.ase import BulkPhaseMaterials\n",
    "\n",
    "bulk = BulkPhaseMaterials(numbers=[1, 2, 3, 4, 5] * 300, \n",
    "                          positions=dataset.props['nxyz'][0][:, 1:4],\n",
    "                          cell=dataset.props['cell'][0],\n",
    "                          pbc=True,\n",
    "                          props=system_prop)\n",
    "bulk.set_masses( [29.0407, 53.0607, 28.052, 29.06, 86.804612] * 300) # mass of cg atoms  \n",
    "bulk.update_nbr_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time[ps]      Etot[eV]     Epot[eV]     Ekin[eV]    T[K]\n",
      "0.0000            95.47        36.34        59.13   305.0\n",
      "\n",
      "0.1000            21.64       -26.89        48.54   250.3\n",
      "\n",
      "0.2000            -0.76       -58.10        57.34   295.7\n",
      "\n",
      "0.3000           -17.30       -75.25        57.95   298.9\n",
      "\n",
      "0.4000           -28.88       -88.50        59.61   307.4\n",
      "\n",
      "0.5000           -39.22       -96.91        57.69   297.5\n",
      "\n",
      "0.6000           -45.44      -103.41        57.97   299.0\n",
      "\n",
      "0.7000           -51.99      -110.02        58.04   299.3\n",
      "\n",
      "0.8000           -56.11      -114.77        58.66   302.6\n",
      "\n",
      "0.9000           -58.09      -116.05        57.97   299.0\n",
      "\n",
      "1.0000           -59.07      -116.75        57.68   297.5\n",
      "\n",
      "1.1000           -64.90      -123.06        58.16   300.0\n",
      "\n",
      "1.2000           -69.72      -128.77        59.05   304.5\n",
      "\n",
      "1.3000           -69.05      -127.78        58.72   302.9\n",
      "\n",
      "1.4000           -75.56      -130.82        55.26   285.0\n",
      "\n",
      "1.5000           -74.37      -131.95        57.58   297.0\n",
      "\n",
      "1.6000           -75.80      -135.90        60.10   310.0\n",
      "\n",
      "1.7000           -76.82      -136.94        60.12   310.1\n",
      "\n",
      "1.8000           -81.98      -141.76        59.78   308.3\n",
      "\n",
      "1.9000           -84.53      -143.83        59.29   305.8\n",
      "\n",
      "2.0000           -85.41      -142.59        57.17   294.9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "timestep = 1\n",
    "steps = 2000\n",
    "temperature = 300\n",
    "\n",
    "path = '{}/ase_T300'.format(OUTDIR)\n",
    "if os.path.exists(path):\n",
    "    print('exists')\n",
    "else:\n",
    "    os.makedirs(path)\n",
    "\n",
    "DEFAULTNVEPARAMS = {\n",
    "    'T_init': temperature, \n",
    "    'thermostat': NoseHoover,   \n",
    "    'thermostat_params': {'timestep': timestep * units.fs, \"temperature\": temperature * units.kB,  \"ttime\": 20.0},\n",
    "    'nbr_list_update_freq': 10,\n",
    "    'steps': steps/timestep,\n",
    "    'save_frequency': 100/timestep,\n",
    "    'thermo_filename': '{}/thermo.log'.format(path, temperature), \n",
    "    'traj_filename': '{}/atoms.traj'.format(path, temperature),\n",
    "    'skip': 0\n",
    "}\n",
    "\n",
    "\n",
    "calc = NeuralFF(model=model, device=0)\n",
    "bulk.set_calculator(calc)\n",
    "nve = Dynamics(bulk, DEFAULTNVEPARAMS)\n",
    "\n",
    "nve.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:htvs] *",
   "language": "python",
   "name": "conda-env-htvs-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
